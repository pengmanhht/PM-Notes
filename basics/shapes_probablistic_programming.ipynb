{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapes and Dimensions\n",
    "\n",
    "https://ericmjl.github.io/blog/2019/5/29/reasoning-about-shapes-and-probability-distributions/\n",
    "\n",
    "https://pyro.ai/examples/tensor_shapes.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Event Shape:** the atomic shape of a single event/observation from the distribution (or batch of distributions of the same family)\n",
    "\n",
    "**Batch Shape:** the atomic shape of a single event/observation from one or more distributions of the same family. We can't have a batch of a Gaussian and a Gamma distribution together, but we can have a batch of more than one Gaussians.\n",
    "\n",
    "**Sample Shape:** the shape of bunch of samples drawn from the distributions\n",
    "\n",
    "Why do these different shapes matter? Just think about the computation of the log likelihood of a vector of two numbers. In the case of bivariate Gaussians and the case of the batch of two independent Gaussians, how many log probabilities should we return?\n",
    "\n",
    "> if problems can be cast into a tensor-space operation, vectorization can help speed up many operations that we wish to handle. -- Eric Ma\n",
    "\n",
    "> apparently same-shaped draws are shaped differently semantically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jax \n",
    "import jax.numpy as np\n",
    "from jax import random \n",
    "\n",
    "# import numpyro\n",
    "import numpyro.distributions as dist \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution Event Shape: ()\n",
      "Distribution Batch Shape: ()\n",
      "Data Shapes: (1,)\n",
      "Samples: [-0.75307846]\n",
      "Log Probability: [-1.2025021]\n"
     ]
    }
   ],
   "source": [
    "# one draw from one normal\n",
    "# event: one draw [scalar]\n",
    "# batch: one normal\n",
    "d = dist.Normal()\n",
    "print(\"Distribution Event Shape:\", d.event_shape)\n",
    "print(\"Distribution Batch Shape:\", d.batch_shape)\n",
    "\n",
    "draw = d.sample(key=random.PRNGKey(123), sample_shape=(1,)) # sample+shape + batch_shape + event_shape\n",
    "print(\"Data Shapes:\",draw.shape)\n",
    "print(\"Samples:\", draw)\n",
    "\n",
    "logp = d.log_prob(draw)\n",
    "print(\"Log Probability:\", logp)\n",
    "\n",
    "# event shape: ()\n",
    "# batch shape: ()\n",
    "# sample shape: (1,)\n",
    "# data shape: (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution Event Shape: ()\n",
      "Distribution Batch Shape: ()\n",
      "Data Shapes: (2,)\n",
      "Samples: [-0.03049826  0.49289012]\n",
      "Log Probability: [-0.9194036 -1.0404088]\n"
     ]
    }
   ],
   "source": [
    "# two draws from one normal \n",
    "# the elementary event of **drawing a single number** did not fundamentally cahnge\n",
    "# (repeat the same event twice)\n",
    "# event: one draw [scalar]\n",
    "# batch: one normal\n",
    "d = dist.Normal()\n",
    "print(\"Distribution Event Shape:\", d.event_shape)\n",
    "print(\"Distribution Batch Shape:\", d.batch_shape)\n",
    "\n",
    "draw = d.sample(key=random.PRNGKey(123), sample_shape=(2,)) # sample+shape + batch_shape + event_shape\n",
    "print(\"Data Shapes:\",draw.shape)\n",
    "print(\"Samples:\", draw)\n",
    "\n",
    "logp = d.log_prob(draw)\n",
    "print(\"Log Probability:\", logp)\n",
    "\n",
    "# event shape: ()\n",
    "# batch shape: ()\n",
    "# sample shape: (2,)\n",
    "# data shape: (2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution Event Shape: ()\n",
      "Distribution Batch Shape: (2,)\n",
      "Data Shapes: (1, 2)\n",
      "Samples: [[0.96950173 1.4786704 ]]\n",
      "Log Probability: [[-0.9194036 -2.1390214]]\n"
     ]
    }
   ],
   "source": [
    "# one draw from the first normal alongside one draw from the second normal, \n",
    "# then concatenate them into a vector \n",
    "# drawing number from INDEPENDENT Gaussians\n",
    "# event: one draw\n",
    "# batch: two normals\n",
    "means = np.array([1., 0.])\n",
    "stds = np.array([1., 3.])\n",
    "\n",
    "d = dist.Normal(means, stds)\n",
    "print(\"Distribution Event Shape:\", d.event_shape)\n",
    "print(\"Distribution Batch Shape:\", d.batch_shape)\n",
    "\n",
    "draw = d.sample(key=random.PRNGKey(123), sample_shape=(1,))\n",
    "print(\"Data Shapes:\",draw.shape)\n",
    "print(\"Samples:\", draw)\n",
    "\n",
    "logp = d.log_prob(draw) # computed independently\n",
    "print(\"Log Probability:\", logp)\n",
    "\n",
    "# event shape: ()\n",
    "# batch shape: (2,)\n",
    "# sample shape: (1,)\n",
    "# data shape: (1, 2) # rightmost is the batch_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution Event Shape: (2,) [2-element vector]\n",
      "Distribution Batch Shape: ()\n",
      "Data Shapes: (1, 2)\n",
      "Samples: [[-0.03049826  0.41160622]]\n",
      "Log Probability: [-1.8159714]\n"
     ]
    }
   ],
   "source": [
    "# one draw from a multivariate Gaussian\n",
    "# event: one draw with 2 elements [2-element vector]\n",
    "d = dist.MultivariateNormal(covariance_matrix=np.array([[1., 0.5],[0.5,1.]]))\n",
    "print(\"Distribution Event Shape:\", d.event_shape, \"[2-element vector]\")\n",
    "print(\"Distribution Batch Shape:\", d.batch_shape)\n",
    "\n",
    "draw = d.sample(key=random.PRNGKey(123), sample_shape=(1,))\n",
    "print(\"Data Shapes:\",draw.shape)\n",
    "print(\"Samples:\", draw)\n",
    "\n",
    "logp = d.log_prob(draw) # computed with consideration to the full join distribution\n",
    "print(\"Log Probability:\", logp)\n",
    "# event shape: (2,)\n",
    "# batch shape: ()\n",
    "# sample shape: (1,)\n",
    "# data shape: (1,2) # rightmost is the event_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution Event Shape: (2,) [2-element vector]\n",
      "Distribution Batch Shape: ()\n",
      "Data Shapes: (2, 2)\n",
      "Samples: [[-0.1470326 -2.3694336]\n",
      " [ 1.648498   0.5994194]]\n",
      "Log Probability: [-5.2190027 -3.0865078]\n"
     ]
    }
   ],
   "source": [
    "# two draws from a multivariate Gaussian\n",
    "# event: two draws with 2 elements [2-element vectors]\n",
    "d = dist.MultivariateNormal(covariance_matrix=np.array([[1., 0.5],[0.5,1.]]))\n",
    "print(\"Distribution Event Shape:\", d.event_shape, \"[2-element vector]\")\n",
    "print(\"Distribution Batch Shape:\", d.batch_shape)\n",
    "\n",
    "draw = d.sample(key=random.PRNGKey(123), sample_shape=(2,))\n",
    "print(\"Data Shapes:\",draw.shape)\n",
    "print(\"Samples:\", draw)\n",
    "\n",
    "logp = d.log_prob(draw) # computed with consideration to the full join distribution\n",
    "print(\"Log Probability:\", logp)\n",
    "# event shape: (2,)\n",
    "# batch shape: ()\n",
    "# sample shape: (2,)\n",
    "# data shape: (2,2) # rightmost is the event_shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
